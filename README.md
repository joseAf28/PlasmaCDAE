## Autoencoder Enhanced Surrogate Model

### Introduction

This work presents a progressive Conditional Denoising Autoencoder (CDAE) model designed for efficiently solving steady-state problems associated with plasma-surface interactions. Specifically, the model tackles equilibrium states described mathematically by the deterministic equation:
$$
F(\vec{x}, \vec{y}) = 0
$$
Here, $\vec{x}$ represents known input parameters, and  $\vec{y}$  denotes corresponding equilibrium outputs.



### Problem Formulation and Previous Works

The primary objective is developing a robust surrogate model that accurately predicts equilibrium outputs based on specific input conditions. The equilibrium dataset is generated from solutions of deterministic steady-state differential equations modeling plasma-surface interactions.

So, far the approaches have been explored included predicted $\vec{y}$ directly from the $\vec{x}$ conditions using MLP models,  which effectively means that each of the predicted components $\hat{y}_i$ only effectively depends on the connections established betwen  the $\vec{x}$ components and their high-level representations, so that our problem is given by obtain the $f(\vec{x}; \theta)$, such that the pairs $(\vec{x}, f(\vec{x}))$ approximately satisfy $F(\vec{x}, f(\vec{x};\theta)) = 0$.

Recently, the projection method was presented. It comprises train the system $(\vec{x}, f(\vec{x}; \theta))$ using a MLP model , define the physical constraints as equations $g(\vec{x}, \vec{y}) = 0$ and then project the predicted output $\hat{y}$ onto the constraint manifold by solving the following optimization problem:
$$
min⁡_p ∥p−f(x;Θ)∥_W^2 ~~ \text{s.t} ~~ g(x,p)=0
$$
In this way, tthe model predictions always comply with the specified physical laws, even if the model itself didn’t learn them well during training.



The objective of this work follows a different direction. Inspired by the fact that the pairs $(\vec{x}, \vec{y})$ are the fixed point solutions of $F(\vec{x}, \vec{y}) = 0$, we aspire to find a formulation that generally internalizes and learn the structure within $(\vec{x}, \vec{y})$ and not solely stick to connections established between $\vec{x}$ and/or through the constraints $g(\vec{x}, \vec{y}) =0$. 



### Dataset

The dataset is externally sourced from previously published work and made publicly available on GitHub LINK. It comprises $3000$  input-output pairs $(\vec{x}, \vec{y})$, capturing equilibrium conditions across a variety of scenarios. In this system, $\vec{x}$ corresponds to th vector of experimental conditions and $\vec{y}$ corresponds to the vector of the chemical species concentrations. The details of how it was generated and about the physical simulator are widely explained in REF Projection.



### Model Architecture: Conditional Denoising Autoencoder (CDAE)

The CDAE model is central to our methodology. It is designed to reconstruct equilibrium states from artificially corrupted versions of the outputs $\vec{y}$, conditioned explicitly on inputs $\vec{x}$. Formally, the CDAE operates as follows:

- **Noisy Inputs**: Given the original equilibrium output $y$, a corrupted version $\tilde{y}$ is generated by adding  noise $\varepsilon$:
  $$
  \tilde{y} = y + \varepsilon, ~~~~\varepsilon \sim N(0, \sigma^2)
  $$
  
- **Conditional Reconstruction**: The CDAE aims to reconstruct $y$ from the noisy observation  $\tilde{y}$  conditioned on inputs $\vec{x}$:
  $$
  \hat{y} = g_\phi(\tilde{y}, x)
  $$

- **Loss Function**: Training involves minimizing the mean squared reconstruction error between the true equilibrium outputs and their CDAE reconstructions:
  $$
  \mathcal{L}_{CDAE}(\phi) = \mathbb{E}[\|g_\phi(\tilde{y}, x) - y\|^2_2]
  $$

- **Corrective Vector Field**: Post-training, the CDAE implicitly defines a deterministic corrective vector field:
  $$
  v(y; x; \sigma) = g_\phi(y; x; \sigma) - y
  $$
  This vector field guides iterative refinements toward equilibrium solutions.



Moreover, rather than using a fixed noise level, a noise schedule allows the model to see examples with varying levels of corruption during training. This enables the model to learn robust robust corrections across a spectrum of deviations from the manifold.



### Relationship to Denoising Score Matching

Our CDAE approach parallels the principles behind denoising score matching, commonly applied in stochastic generative models. Score matching involves learning gradients of log probability densities from noisy observations. However, in our deterministic context, instead of learning stochastic gradients, the CDAE directly learns a deterministic correction field. Hence, while inspired by denoising score matching, our approach diverges by leveraging deterministic equilibrium conditions rather than stochastic processes.

Moreover, architectures like diffusion and score-based models apply a gradual denoising process (starting from high noise to low noise) to recontruct clean samples. Here, applying a noise schedule likewise help the CDAE "navigate " and correct trajectories  from high-noise (off-manifold) states to low-noise, equilibrium states.



### Refinement Dynamics

The refinement dynamics process combines an initial prediction and iterative updates driven by a corrective vector field. It includes the following steps:

- **Initial Estimate with Direct Prediction**

$$
\hat{y} = f_\theta(x)
$$

​	The function $f_{\theta}(x)$ provides an initial guess of the equilibrium state given the input $x$. Although $\hat{y}$ might be close to the manifold, further refinement is needed for convergence.

- **Iterative Refinement**

​	The model iteratively refines the initial estimate using a learned corrective vector field derived from the denoising autoencoder (CDAE). At iteration $k$, the state is updated as:
$$
y^{(k+1)} = y^{(k)} + \eta~ v(y^{(k)}; x), \quad y^{(0)} = \hat{y}
$$
where $v(y^{(k)};x)=g_{\phi}(y^{(k)};x)−y^{(k)}$ and $\eta$ is the step size, tuning the magnitude of each update.

- **Incorporating Annealing Noise Schedule**

  To improve convergence, the system employs an annealing noise schedule that adapts the noise variance σkσk over the iterations. The update rule, which now explicitly accounts for the noise level, is given by:
  $$
  y^{(k+1)} = y^{(k)} + \eta \left( g_{\phi}(y^{(k)}; x; \sigma_k) - y^{(k)}\right)
  $$
  where the $\sigma_k$ is the noise variance, Initially set to relative high value, the noise variance is gradually decreased with the iteractions. This approach helps the model correct large deviations in the early stages and fine-tune the estimate in later iterations.

  This approch constitutes works as an adaptive correction method: higher noise levels assist in navigating larger errors by providing broader corrective signals whereas lower noise levels enable precise adjustments as the solution nears equilibrium.

- **Convergence Criterion**

  The equilibrium state $y^*$ is reached when the corrective vector vanishes:
  $$
  v(y^*; x) = g_{\phi}(y^*;x) - x
  $$
  Equivalently, convergence is defined by the norm of the corrective vector field falling below a small threshold $\epsilon$:
  $$
  ∥ v(y^{(k)};x)∥_2  < \epsilon
  $$
  This threshold-based criterion ensures that the updates become negligibly small, indicating that $y^{(k)}$is essentially at an equilibrium state.

- **Clipping of Updates**

  To maintain stability in the refinement dynamics and prevent the algorithm from overshooting the local basin of attraction, clipping of the vector field updates is employed. This means that if the magnitude of the update $\eta v(y^{(k)};x)$ exceeds a predetermined threshold, the update is scaled back:
  $$
  \Delta y^{(k)} = \text{clip}\left( \eta v(y^{(k)};x), \text{min}= -c, \max = c \right)
  $$
  where $c$ is the clipping constant. Clipping ensures that no single update is too large, preserving the local convergence properties and mitigating the risk of diverging from the equilibrium basin.

  

### Training Methodology

The training stages correspond to two independent steps:

- **Direct Predictor Training**: Optimized by minimizing direct prediction error $\mathcal{L}_{pred}$.
- **CDAE Training**: Conducted independently, focusing on minimizing denoising reconstruction loss $\mathcal{L}_{CDAE}$.

The noise scheduling chose corresponds to 10 equally spaced levels betwen $0.3$ and $10^{-4}$. The *Adam* optimizer was chosen with $\text{lr}=10^{-3}$ . The train and test sets have $2700$ and $300$ samples respectively and a batch size of 32.  When training the progressive CDAE the all levels of noise present the same weighting (1) for the loss function. 

For the direct predictor, we further use the $l_2$ weights regularization with $\lambda_{reg} = 10^{-4}$ and it consists of an MLP model with 2 hidden layers and the ReLu function with 4217 parametes.

Describe the autoencoder



### Results

- **Direct Predictor Alone**: Achieved RMSE of 0.0380.
- **CDAE Refinement**: Significantly reduced RMSE to 0.0180.
- Dataset: 2700 training samples, 300 test samples.
- CDAE Parameters: 23,548.
- Iterative refinement parameters: \( K = 700 \), learning rate \( \eta = 10^{-3} \).



Gain of 50% in RMSE loss of the test set.



Comparison with an MLP model with 30000 parameters 



### Conclusion

The CDAE surrogate model effectively improves accuracy and reliability for predicting equilibrium states in deterministic plasma-surface interaction scenarios compared to direct predictors and autoregressive approaches.





### References

[Relevant references included here]

### Appendix

[Optional: Detailed hyperparameter tuning, training convergence plots, supplementary figures, and experimental details].





### Autoregressive Model (Experimental Approach)

We explored an alternative autoregressive model characterized by predicting output components sequentially:

- **Autoregressive Decomposition**: Each component \( y_i \) of the output \( y \) is predicted sequentially, conditioned on inputs \( x \) and all previously predicted components:

  \[ \hat{y}_i = h_i([f(x), \hat{y}_1, \hat{y}_2, \dots, \hat{y}_{i-1}]) \]

- **Shared Backbone Network**: Input parameters \( x \) are first transformed by a shared neural backbone network \( \phi(x) \) into a common latent space. Each sequential prediction is then performed by specific subnetworks \( h_i(\cdot) \).

- **Teacher Forcing with Cosine Scheduling**: During training, ground truth components \( y_j \) and predicted components \( \hat{y}_j \) are mixed according to a cosine annealing schedule:

  \[
  y_j^{input} = \begin{cases}
  y_j^{true}, & \text{with probability } p(t) \\
  \hat{y}_j, & \text{with probability } 1 - p(t)
  \end{cases}
  \]

  where the scheduling function \( p(t) \) is defined by:

  \[ p(t) = p_{\text{min}} + \frac{1}{2}(p_{\text{max}} - p_{\text{min}})\left(1 + \cos\left(\pi \frac{t}{T}\right)\right) \]

- **Residual Correction Network**: An additional correction network computes residual corrections \( \Delta y \), refining the base autoregressive predictions:

  \[ \hat{y}_{\text{final}} = \hat{y}_{\text{base}} + \Delta y \]

Despite detailed experimentation, this autoregressive model was less effective than the CDAE-based model.